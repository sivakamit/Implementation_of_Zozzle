Malware detection

```{r}
options(scipen = 999)
cwFile <- read.csv('D:/projects/Crypto research/code/data.csv')
df <- cwFile # use an alternative data frame
cat("This database has", nrow(df), "rows and", ncol(df), "columns")
```
Illustrating all names of columns

```{r}
names(df)
```
Quick description of the dataset;

```{r}
str(df)
```
Barplot

```{r}
par(mar=c(7.1, 7.1, 7.1, 2.1),mgp=c(3, 2, 0),las=0) #sets graphic grid to 2 by 2 with margin spacing
labelFreqs <- table(df$having_Sub_Domain) # frequency of Result
barplot(labelFreqs,col = grey.colors(3), main="Websites that have sub domain")  # Shows the frequency of having sub domain;
```

check for missing values

```{r}
colSums(is.na(df))
```

standardize and normalise

```{r}
dat <- data.frame(x = rnorm(10, 30, .2), y = runif(10, 3, 5))
scaled.dat <- scale(dat)
#check that we get mean of 0 and sd of 1
colMeans(scaled.dat) # a version of apply(scaled.dat, 2, mean)
apply(scaled.dat, 2, sd)
```

```{r}
library(dplyr)
library(caret)
library(ISLR)
```

Creating the model

Model - 1

```{r}
idTrainOne <- createDataPartition(df$Result, p=0.8,list=FALSE, times=1)
# this time we are dividing the data into a 80% training set and a 20% test set
trainOne <- df[idTrainOne,] # training set with p = 0.8
sid <- as.numeric(rownames(trainOne))
testOne <- df[-sid,] # test set with p = 0.2
set.seed(201)
prop.table(table(trainOne$Result))
```

```{r}
ctrlOne = trainControl(method = "cv", number = 10)
# increasing the number variable by 5 (the previous model in section two is just 5)
trainOne$Result = as.factor(trainOne$Result)
fitModelOne <- train(Result ~ ., data=trainOne,
                     method="rf", # again with random forest
                     trControl=ctrlOne,
                     ntree=201)
# increasing the number of trees to be with 196 more than the one in the previous model
predOne <- predict(fitModelOne, testOne[,-ncol(testOne)]) #predict using the new model
testOne <- cbind(testOne,predOne)
resultsOne <- confusionMatrix(table(testOne$predOne, testOne$Result))
accuracyOne <- sum(diag(resultsOne$table))/nrow(testOne)
cat('Accuracy is ', accuracyOne) 
```

```{r}
aLabelOne <- table(df$Result) # frequency of Result
barplot(aLabelOne,col = grey.colors(3), main="Results after modelling and predicting")
```


```{r}
print(fitModelOne)
```


Model - 2

with 70% training set and 30% test set

```{r}
idTrainTwo <- createDataPartition(df$Result, p=0.7,list=FALSE, times=1)
# dividing the data 70% training set and 30% test set
trainTwo <- df[idTrainTwo,] # training set with p = 0.7
sid <- as.numeric(rownames(trainTwo))
testTwo <- df[-sid,] # test set with p = 0.3
set.seed(99) #set seed for reproducibility
library(randomForest) # using randomforest libarary
prop.table(table(trainTwo$Result))
```

```{r}
ctrlTwo = trainControl(method = "cv", number = 10)
# increasing the number variable by 5 (the previous model in section two is just 5)
trainTwo$Result = as.factor(trainTwo$Result)
fitModelTwo <- train(Result ~ ., data=trainTwo,
                     method="rf", # again with random forest
                     trControl=ctrlTwo,
                     ntree=201)
# increasing the number of trees to be with 196 more than the one in the previous model
predTwo <- predict(fitModelTwo, testTwo[,-ncol(testTwo)]) #predict using the new model
testTwo <- cbind(testTwo,predTwo)
resultsTwo <- confusionMatrix(table(testTwo$predTwo, testTwo$Result))
accuracyTwo <- sum(diag(resultsTwo$table))/nrow(testTwo)
cat('Accuracy is ', accuracyTwo)
```

```{r}
aLabelTwo <- table(df$Result) # frequency of Result
barplot(aLabelTwo,col = grey.colors(3), main="Results after modelling and predicting")

```

```{r}
print(fitModelTwo)
```

